{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transform(file, cols, zone_df):\n",
    "    \"\"\" Función que nos lee el file indicado usando las columnas deseadas y utiliza el dataframe zone_df\n",
    "    para hacer ciertas transformaciones en el dataframe final deseado\"\"\"\n",
    "\n",
    "    \n",
    "    #     Leemos el archivo con las columnas deseadas\n",
    "    df = pd.read_csv(file,usecols=cols, parse_dates=[0,1])\n",
    "   #     Nos quedamos con 120k líneas al azar y yambiamos el nombre a las columnas por unos más \n",
    "   #     intuitivos y más cortos\n",
    "    df = df.sample(120000)\n",
    "    \n",
    "    df = df.rename(\n",
    "    columns={\"tpep_pickup_datetime\" : \"PU_datetime\" \n",
    "            , \"tpep_dropoff_datetime\" : \"DO_datetime\"\n",
    "            , \"trip_distance\" : \"distance_miles\"\n",
    "            , \"PULocationID\" : \"PULocID\"\n",
    "            , \"DOLocationID\" : \"DOLocID\"\n",
    "            , \"tip_amount\" : \"tip\"\n",
    "            , \"total_amount\" : \"total\"})\n",
    "    \n",
    "#     Queremos hacer clasificaciones en función del barrio en el que surjan y acaben los viajes, por lo que\n",
    "#     añadimos estas dos columnas, de momento vacías\n",
    "    df['PUBorough'] = np.nan\n",
    "    df['DOBorough'] = np.nan\n",
    "    \n",
    "#    En el dataframe con las zonas hemos eliminado un par de IDs, por lo que debemos asegurarnos que en el \n",
    "#    dataframe con la info de los viajes no los contenga. Para ello creamos unos set de comparación con las \n",
    "#    columnas que contienen los ID\n",
    "    zones_set = set(zone_df.LocationID.values)\n",
    "    PU_set = set(df.PULocID.values)\n",
    "    DO_set = set(df.DOLocID.values)\n",
    "    \n",
    "#     Mediante los dos siguientes bucles quitamos los IDs que están en el dataframe de los viajes que no \n",
    "#     estén en el DataFrame con las zonas. Uno es para el origen de los viajes y otro para el fin\n",
    "    for val in PU_set.difference(zones_set):\n",
    "        df = df.loc[df['PULocID'] != val]\n",
    "        \n",
    "    for val in DO_set.difference(zones_set):\n",
    "        df = df.loc[df['DOLocID'] != val]\n",
    "        \n",
    "#     Ya podemos rellenar las columnas de los barrios en el dataframe de los viajes, para ellos buscamos \n",
    "#     coicidencias en el ID entre los dos dataframes que tenemos y vamos metiendo valores\n",
    "    for val in set(df['PULocID'].values):\n",
    "        df.loc[df['PULocID'] == val, 'PUBorough'] = zone_df.loc[zone_df['LocationID'] == val, 'Borough'].values[0]\n",
    "    \n",
    "    for val in set(df['DOLocID'].values):\n",
    "        df.loc[df['DOLocID'] == val, 'DOBorough'] = zone_df.loc[zone_df['LocationID'] == val, 'Borough'].values[0]\n",
    "        \n",
    "#     Nos quedaremos con el momemnto en el que se inicia el viaje y la duración del viaje. Esta última \n",
    "#     columna la creamos restando final - inicio y haciendo las transformaciones necesarias\n",
    "    df['trip_duration_min'] = (df.DO_datetime - df.PU_datetime).astype('timedelta64[s]')\n",
    "    df['trip_duration_min'] = round(df['trip_duration_min']/60,2)\n",
    "    \n",
    "#    Mi intención es quedarme con aquellos viajes cuyo origen y destinto están en el mismo barrio para \n",
    "#    comprobar las hipótesis deseadas\n",
    "\n",
    "#     df = df.loc[df['PUBorough'] == df['DOBorough']] \n",
    "#   Parece que tarda algo menos la negación de la desigualdad así que nos quedamos con ella\n",
    "    df = df.loc[~(df['PUBorough'] != df['DOBorough'])]\n",
    "    \n",
    "#   Como nos hemos quedado con los viajes cuyo inicio y fin son en el mismo barrio, podemos borrar una \n",
    "#   columna y así ahorramos algo de espacio. En la misma línea, eliminamos la columna con el tiempo en el\n",
    "#   que se termina el viaje\n",
    "    df = df.rename(columns={\"PUBorough\" : \"Borough\" })\n",
    "    df = df[['PU_datetime','Borough','trip_duration_min','distance_miles','tip','total']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero leemos el archivo que contiene las correspondencias entre los ID y los barrios de Nueva York\n",
    "zones = pd.read_csv(\"zones.csv\")\n",
    "\n",
    "# Eliminamos aquellas filas que tienen un barrio desconocido o que no está entre los 5 conocidos\n",
    "zones = zones[(zones.Borough != \"EWR\") & (zones.Borough != \"Unknown\")]\n",
    "\n",
    "# Esta es la lista de columnas que queremos conservar del archivo que leemos\n",
    "columns_desired = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"trip_distance\",\n",
    "                   \"PULocationID\",\t\"DOLocationID\", \"tip_amount\", \"total_amount\"]\t\n",
    "    \n",
    "files = ['jan_2019.csv', 'apr_2019.csv', 'jul_2019.csv', 'oct_2019.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan = read_transform('jan_2019.csv',columns_desired, zones)\n",
    "Feb = read_transform('feb_2019.csv',columns_desired, zones)\n",
    "Mar = read_transform('mar_2019.csv',columns_desired, zones)\n",
    "Apr = read_transform('apr_2019.csv',columns_desired, zones)\n",
    "May = read_transform('may_2019.csv',columns_desired, zones)\n",
    "Jun = read_transform('jun_2019.csv',columns_desired, zones)\n",
    "Jul = read_transform('jul_2019.csv',columns_desired, zones)\n",
    "Aug = read_transform('aug_2019.csv',columns_desired, zones)\n",
    "Sep = read_transform('sep_2019.csv',columns_desired, zones)\n",
    "Oct = read_transform('oct_2019.csv',columns_desired, zones)\n",
    "Nov = read_transform('nov_2019.csv',columns_desired, zones)\n",
    "Dec = read_transform('dec_2019.csv',columns_desired, zones)\n",
    "taxi_2019 = pd.concat([Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = len(Jan)+len(Feb)+len(Mar)\n",
    "q2 = len(Apr)+len(May)+len(Jun)\n",
    "q3 = len(Jul)+len(Aug)+len(Sep)\n",
    "q4 = len(Oct)+len(Nov)+len(Dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = taxi_2019.iloc[range(0,q1),:]\n",
    "Q2 = taxi_2019.iloc[range(q1,q1+q2),:]\n",
    "Q3 = taxi_2019.iloc[range(q1+q2,q1+q2+q3),:]\n",
    "Q4 = taxi_2019.iloc[range(q1+q2+q3,q1+q2+q3+q4),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.to_csv('Q1.csv',header=True,index=True)\n",
    "Q2.to_csv('Q2.csv',header=True,index=True)\n",
    "Q3.to_csv('Q3.csv',header=True,index=True)\n",
    "Q4.to_csv('Q4.csv',header=True,index=True)\n",
    "taxi_2019.to_csv('taxi_2019.csv',header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
